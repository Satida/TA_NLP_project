{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequential.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"fJ0LpPBHV2Ol","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Dec 18 06:00:06 2019\n","\n","@author: satida\n","\"\"\"\n","\n","\n","from Satida.Layers import ReaderXML,Tokenizer,StopWord,Dictionary,Replacement,Compress,Posting,PostingCompress\n","from Satida.BTtree import BTree\n","\n","\n","\n","class Sequential:\n","    \n","    \n","    def __init__(self):\n","        \n","        self.model=list()\n","        self.docs=None\n","        self.tokens=None\n","        self.tokens_sw=None\n","        self.dict=None\n","        self.rpc=None\n","        self.comp=None\n","        print(\"MODEL\")\n","\n","        \n","    \n","    def add(self,Layer):\n","        \"\"\"\n","        add()\n","        ------\n","        \n","        Satida.Sequential.add (method)\n","        \n","        Params :\n","        ------\n","        Layer : Satida.Layers.object as input):\\n\n","        \n","        return :\n","        ---------\n","        nothing\n","        \"\"\"\n","        self.model.append(Layer)\n","    \n","    \n","    def fit(self):\n","        \"\"\"\n","        via this method you can run your model.\\n \n","        this method dose not return any value as result.\n","        \n","        PrintSize :\n","        ------------\n","        \n","        after finished process save model in directory and print size of it .\n","        \"\"\"\n","        for ly in self.model:\n","            if type(ly) == type(ReaderXML([\"null\"],[\"null\"])):\n","                try :\n","                    self.docs,self.org_Docs=ly.execute()\n","                    print(\"ReaderXML Finished !\")\n","                except:\n","                    raise Exception('there is a problem in Reading XML Files !')\n","            \n","            elif type(ly) == type(Tokenizer()):\n","                try:\n","                    self.tokens_docs=ly.execute(self.docs)\n","                    temp=list()\n","                    for doc in self.tokens_docs:\n","                        temp+=doc\n","                    self.tokens = temp[:]\n","                    del temp\n","                    print(\"Tokenizer Finished !\")\n","                except:\n","                    raise Exception('there is a problem in Reading XML Files or Tokenizer !')\n","                    \n","            elif type(ly) == type(StopWord([\"null\"])):\n","                self.tokens_sw=ly.execute(self.tokens)\n","                self.stopword_tool=ly.execute\n","                print(\"StopWord Finished !\")\n","            \n","            elif type(ly) == type(Dictionary()):\n","                if self.tokens_sw != None:\n","                    self.dict=ly.execute(self.tokens_sw)\n","                else :\n","                    self.dict=ly.execute(self.tokens)\n","                print(\"Dictionary Finished !\")\n","            \n","            elif type(ly) == type(Replacement()):\n","                self.rpc=ly.execute(self.dict)\n","                print(\"Replacement Finished !\")\n","            \n","            \n","            elif type(ly) == type(Posting()):\n","                self.rep_to_dict,self.posting=ly.execute(self.dict,self.rpc,self.tokens_docs)\n","                print(\"Posting Finished !\")\n","            \n","            elif type(ly) == type(PostingCompress(\"Gama\")):\n","                self.posting_compress,self.p_decompress=ly.execute(self.posting)\n","                print(\"PostingCompress Finished !\")\n","            \n","            elif type(ly) == type(Compress(\"Full\")):\n","                try:\n","                    if self.rpc != None:\n","                        self.comp=ly.execute(self.rpc)\n","                    else :\n","                        self.comp=ly.execute(self.dict)\n","                    print(\"Compress Finished !\")\n","                    # pickle \n","                    #with open(\"Normal.pkl\",\"wb\") as f:\n","                        #pickle.dump(self.comp,f)\n","                except:\n","                    raise Exception('there is a problem in Replacement or Dictionary !')\n","        \n","            elif type(ly) == BTree:\n","                self.tree=ly\n","                mode=ly.name\n","                if mode == \"Simple\":\n","                    ly.execute(None)\n","                    if self.rpc != None:\n","                        ly.Insert(self.rpc)\n","                    else :\n","                        ly.Insert(self.dict)\n","                    \n","                    ly.PrintSize()\n","                else :\n","                    ly.execute(self.comp[\"String\"])\n","                    ly.Insert(self.comp[\"indexes\"])\n","                    ly.PrintSize()\n","            \n","                \n","            \n","    def __intersection(self,lst):\n","      lst1= lst[0]\n","      for lst2 in lst[1:]:\n","        lst1 = [value for value in lst1 if value in lst2] \n","       \n","      return lst1          \n","                \n","\n","    def Search(self,items:str):\n","      useful_docs=list()\n","      for item in self.stopword_tool(items.split(\" \")):\n","        result_str,refrence = self.__REDetector(item)\n","        dict_index = self.rep_to_dict[refrence[0]]\n","        if self.posting_compress:\n","          useful_docs.append(self.p_decompress(self.posting_compress)[dict_index])\n","          print(\"Posting decompressed !\")\n","        else :\n","          useful_docs.append(self.posting[dict_index])\n","      result=self.__intersection(useful_docs)\n","      for doc in result:\n","        print(20*\"*\")\n","        self.__print(self.org_Docs[doc].find(\"TITLE\").text)\n","        print(10*\"*\",20*\" \",10*\"*\")\n","        self.__print(self.org_Docs[doc].find(\"TEXT\").text)\n","        print(20*\"*\")\n","      return result_str,refrence\n","\n","            \n","            \n","          \n","    \n","    \n","    def __REDetector(self,word:str):\n","        \n","        from Satida.Utils.Utils import alphabet\n","        import re\n","        \n","        refrences =list()\n","        result = list()\n","        alphabet=\"\".join(alphabet).replace(\"\\n\",\"\")\n","        \n","        if re.match(r\"(\\*[\"+alphabet+\"]+\\*)\",word) != None:\n","            word=word.replace(\"*\",\"\")\n","            res_str,res_ref=self.tree.Search(word)\n","            for i,r in enumerate(res_str):\n","                if word in r:\n","                    result.append(r)\n","                    refrences.append(res_ref[i])\n","                    \n","        elif re.match(r\"([\"+alphabet+\"]+\\*[\"+alphabet+\"]+)\",word) != None:\n","            op1,op2=word.split(\"*\")\n","            res_str,res_ref=self.tree.Search(op2+\"$\"+op1)\n","            for i,r in enumerate(res_str):\n","                if r.startswith(op1) and r.endswith(op2):\n","                    result.append(r)\n","                    refrences.append(res_ref[i])\n","            \n","        elif re.match(r\"([\"+alphabet+\"]+\\*)\",word) != None:\n","            word=word.replace(\"*\",\"\")\n","            res_str,res_ref=self.tree.Search(word)\n","            for i,r in enumerate(res_str):\n","                if r.startswith(word) :\n","                    result.append(r)\n","                    refrences.append(res_ref[i])\n","        \n","        elif re.match(r\"(\\*[\"+alphabet+\"]+)\",word) != None:\n","            word=word.replace(\"*\",\"\")\n","            res_str,res_ref=self.tree.Search(word +\"$\")\n","            for i,r in enumerate(res_str):\n","                if r.endswith(word) :\n","                    result.append(r)\n","                    refrences.append(res_ref[i])\n","                    \n","        elif re.match(r\"([\"+alphabet+\"]+)\",word) != None:\n","            word=word.replace(\"*\",\"\")\n","            res_str,res_ref=self.tree.Search(word +\"$\")\n","            for i,r in enumerate(res_str):\n","                if r == word  :\n","                    result.append(r)\n","                    refrences.append(res_ref[i])\n","        \n","        return result,refrences\n","         \n","    \n","    \n","    def __print(self,text):\n","      for i in range(len(text) // 60 +1):\n","        try:\n","          print(text[i*60:(i+1)*60])\n","        except:\n","          print(\"sdfdfs\")\n","          print(text[i*60:])\n","      \n","        \n","\n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    "],"execution_count":0,"outputs":[]}]}