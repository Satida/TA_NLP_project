{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Layers.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"tvjVesQTPOSa","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Dec 18 05:22:36 2019\n","\n","@author: satida\n","\"\"\"\n","\n","def Compress(mode:str,K=4):\n","    \"\"\"\n","    Satida.Layers.Compress\n","    ---------------------\n","    \n","    Params :\n","    ----------\n","\n","    mode : { Normall , Full , Extra }\n","        \n","    Normall : convert dictionary to a String with \",\" as delemiter \n","        \n","    Full : convert dictionary to k size blocks of word \n","        \n","    Extra : create prefix for every K size blocks of word and delete prefix from all block words.\n","    \n","    Extra Format => prefix % tkn1 - prefix , tkn2- prefix ,tkn3- prefix ,tkn4- prefix\n","        \n","    Return:\n","    --------\n","    \n","    dict :{\"String \": list of Strings, \"Indexes\" :Indexes }\n","    \n","    \n","    \"\"\"\n","    from .Layers_Source.Compress import Compress as cmp\n","    return cmp(mode,K)\n","\n","def Dictionary():\n","    \"\"\"\n","    Satida.Layers.Dictionary\n","    ---------------------\n","    \n","    just make set dictionary for delete all duplicate Tokens\n","    \n","    \"\"\"\n","    from .Layers_Source.Dictionary import Dictionary as dic\n","    return dic()\n","\n","def ReaderXML(xml_dir:list,valid_tags:list):\n","    \"\"\"\n","    Satida.Layers.ReaderXML\n","    ---------------------\n","    \n","    Params :\n","    ----------\n","    xml_dir : list of all .xml file directions\n","    \n","    valid_tags : list of tags you need to proces\n","    \n","    *Note : first layer in model.\n","    \n","    \n","    \"\"\"\n","    from .Layers_Source.ReaderXML import ReaderXML as reader\n","    return reader(xml_dir,valid_tags)\n","\n","def Replacement():\n","    \"\"\"\n","    Satida.Layers.Replacement\n","    ---------------------\n","    \n","    Example :\n","    ----------\n","    \n","    Satida = satida$ - atida$s - tida$sa - ida$sat -da$sati - a$satid \n","    \n","    \"\"\"\n","    from .Layers_Source.Replacement import Replacement as rpc\n","    return rpc()\n","\n","def StopWord(stop_words:list):\n","    \"\"\"\n","    Satida.Layers.StopWord\n","    ---------------------\n","    \n","    Params :\n","    ----------\n","    stop_words : list of all Stop words\n","    \n","    Example :\n","    -----------\n","    \n","    stop_word =[\"the\", \"in\"]\n","    \n","    >>> Satida is best developer in the world\n","    \n","    >>> [Satida ,is ,best ,developer ,world ]\n","    \n","    \"\"\"\n","    from .Layers_Source.StopWord import StopWord as sw\n","    return sw(stop_words)\n","\n","def Tokenizer():\n","    \"\"\"\n","    Satida.Layers.Tokenizer\n","    ---------------------\n","    \n","    Example :\n","    ----------\n","    \n","    AI With Satida => [AI , With , Satida] \n","    \n","    \"\"\"\n","    from .Layers_Source.Tokenizer import Tokenizer as tkn\n","    return tkn()\n","\n","\n","def Posting():\n","    \"\"\"\n","    Satida.Layers.Posting\n","    ---------------------\n","    \n","    \n","    \"\"\"\n","    from .Layers_Source.Posting import Posting as pst\n","    return pst()\n","\n","\n","\n","def PostingCompress(mode:str):\n","  \"\"\"\n","  Satida.Layers.PostingCompress\n","    ---------------------\n","\n","  this layer can compress in two type {Gama , ContinueBit}\n","\n","  Example:\n","  ==============\n","  Gama [2 , 5] => [2 , 3] ---> [10,0,10,1] ---> 100101\n","\n","  ContinueBit [2 , 5] => [2 , 3] --> [10000010 , 10000011]\n","  \"\"\"\n","  from .Layers_Source.PostingCompress import PostingCompress as psc\n","  return psc(mode)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]}]}